meta:
  version:  'v0.0.1'
  language:  'jp_800_5'
  root:       "checkpoint"
  root_data:  f"{ns.meta.root}/{ns.meta.language}"
  output_file: f"{ns.meta.root_data}/output.txt"

model:
  id: f"asr_{ns.meta.language}_{ns.meta.version}"
  rnn_hidden_size:    800
  rnn_hidden_layers:  5
  rnn_type:           nn.GRU
  context:            20
  bidirectional:      true
  label_path: f"{ns.meta.root_data}/labels.json"
  model_path: f"{ns.meta.root_data}/model.pth"
  decoder:
    top_paths:    1
    beam_width:   10
    lm_path:      null
    alpha:        0.8
    beta:         1
    cutoff_top_n: 40
    cutoff_prob:  1.0
    lm_workers:   1
  audio_conf:
    sample_rate:          16000
    window_size:          .02
    window_stride:        .01
    window:               'hamming'
    speed_volume_perturb: false
    spec_augment:         false
    noise_dir:            null
    noise_prob:           0.4
    noise_min:            0.0
    noise_max:            0.5

trainer:
  log_dir:                  'visualize/deepspeech_final'
  batch_size:               10
  cuda:                     True
  num_workers:              32
  epochs:                   1000
  start_epoch:              0
  silent:                   false
  checkpoint_per_batch:     0
  visdom:                   false
  tensorboard:              false
  log_params:               false
  finetune:                 false
  shuffle:                  true
  seed:                     123456
  continue_from: f"{ns.model.model_path}"
  train_manifest: f"{ns.meta.root_data}/train.json"
  val_manifest: f"{ns.meta.root_data}/test.json"
  output_file: f"{ns.meta.output_file}"
  save_folder: f"{ns.meta.root_data"}
  metrics:
    loss: []
    wer: []
    cer: []
  optim:
    max_norm:             400
    learning_anneal:      1.005
    keep_batchnorm_fp32:  null
    loss_scale:           1
    opt_level:            'O1'
    lr:                   0.0003
    momentum:             0.9
    sorta_grad:           true
    nesterov:             true
    weight_decay:         0.00001
    gamma: 0.7
    step: 1
  dist:                   null

inference:
  cuda:         true
  half:         false
  manifest:     f"{ns.meta.root_data}/test.json"
  output_file:  f"{ns.meta.output_file}"
  batch_size:   f"{ns.trainer.batch_size}"
  num_workers:  f"{ns.trainer.num_wokers}"
  restart_from: "zakuro://asrdeepspeech/jp_800_5"

windows:
  'hamming':    "scipy.signal.hamming"
  'hann':       "scipy.signal.hann"
  'blackman':   "scipy.signal.blackman"
  'bartlett':   "scipy.signal.bartlett"

supported_rnns:
  'lstm':       "nn.LSTM"
  'rnn':        "nn.RNN"
  'gru':        "nn.GRU"
